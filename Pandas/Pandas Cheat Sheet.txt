Create Series:
1. pandas.Series(data=list,name='Series _name')
2. pandas.Series(data=list1, index=list2,name='Series _name')
3. pandas.Series(data=dictionary,name='Series _name')
4. Dataframe['Column_name']
5. Reading from files
6. pandas.Series(data=Numpy_array, index= list)
-------------------------------------------------------------------------------------------------------

Create Dataframe:
1. pandas.DataFrame(2D list,columns=list of column name)
2. pandas.DataFrame(dictionary)
3. Reading from files

Read and Write to different source: 
1. read_csv(file_name/path) || to_csv(file_name)
2. read_excel(file_name/path) || to_excel(file_name)

Set and Reset Index:
1. Dataframe.set_index(keys, inplace=True)
2. Dataframe.reset_index(inplace=True) 
----------------------------------------------------------------------------------------------------------
Data Preview:
1. DataFrame.head(no. of rows)
2. DataFrame.tail(no. of rows)
3. DataFrame.Sample(no. of rows)  -> Random Preview

Basic Pandas Attributes:
1. DataFrame.info()
2. DataFrame.describe()
3. DataFrame.shape
4. DataFrame.dtype
5. DataFrame.index
6. DataFrame.columns
7. DataFrame.values
8. DataFrame.size
9. DataFrame.name
10. Series or DataFrame['column_name'].is_unique/values
----------------------------------------------------------------------------------------------------------
Fetching columns:
1. DataFrame.column_name
2. DataFrame['column_name']  >> single column , it is a series
3. DataFrame[['c_name_1', 'c_name_2', ...]] >> multiple columns, Francy Indexing
4. DataFrame.loc[:, 'column_name'] or DataFrame.loc[:, ['column1', 'column2']] or DataFrame.loc[:, 'start_column':'end_column']
5. DataFrame.iloc[:, column_index] or DataFrame.iloc[:, [column_index1, column_index2]] or DataFrame.iloc[:, start_index:end_index]
6. DataFrame.filter(['column1', 'column2']) 

Fetching rows :
1. iloc- seraches using index position
DataFrame.iloc[0]  >> data in first position, it is series 
DataFrame.iloc[0:5] >> first 5 data 
DataFrame.iloc[0:5,2]>> alternate data
DataFrame.iloc[[1,3,5]]>> 1,3,5 no. row , francy indexing 

2. loc- searches using index labels
DataFrame.loc['index_name']>> only data in that index
DataFrame.loc['index_name_01': 'index_name_05'] >> kind of slicing
francy indexing is possible

Fetching Both Row and Columns:
dataframe_name.iloc[0:3,0:3]>> 3 columns, 3 rows 
dataframe_name.loc['index_name_1':'index_name_n', 'column_name_01': 'column_name_n']
----------------------------------------------------------------------------------------------------------

Statistical Attributes:
1. DataFrame.mean/median/mode()
2. DataFrame.describe() 
3. DataFrame.sum/min/max  or DataFrame[;column_name'].sum/min/max
4. DataFrame.std/var/corr/cov()
5. DataFrame['column_name'].cumsum/cumprod/cummax/cummin()
6. DataFrame['column_name'].quantile(q) q= 0.25,0.50,0.75,1
7. DataFrame['column_name'].skew/kurt() 
8. Series or DataFrame['column_name'].value_counts() > Frequency counts
9. Series or DataFrame['column_name'].sort_values()  > sort dataframe by values
10. Series or DataFrame['column_name'].sort_index(ascending=False,inplace=True)   > sort dataframe by index
11. Series or DataFrame['column_name'].is_unique
12. Series or Dataframe['column_name'].sort_values(ascending=False/True,inplace=True)

----------------------------------------------------------------------------------------------------------
Rename Columns:
1. DataFrame.rename(columns={'old_1': 'new_1', 'old_2': 'new_2'}, inplace=True)

Adding new column: 
1. Dataframe['column_name']= 'Constant_Value'   >> single and new column with a constant value
2. Dataframe['new_column_name']=dataframe_name['new_column_name'] (do some operation on this)  >> using old column
3. Dataframe['New_Column'] = df['Existing_Column1'] + df['Existing_Column2']  >> or any other operations
4. Dataframe['New_Column'] = np.where(df['Condition_Column'] > Threshold_Value, 'High', 'Low')  >Threshold_Value: values based on which decision making will go on.

Type Casting:
1. Dataframe['column_name']= dataframe_name['column_name'].astype('type')

----------------------------------------------------------------------------------------------------------
Null Checking :
1. Dataframe.isnull() or Dataframe['column_name'].isnull() or Dataframe.isnull().sum()
2. Dataframe.notnull() or Dataframe['column_name'].notnull() 
3. Retrive: Dataframe[Dataframe['column_name'].isnull()]  or Dataframe[Dataframe.isnull().any(axis=1)] 
4. Dataframe.dropna()

Duplicate Checking:
1. Dataframe.duplicated() or duplicated(subset=['column1', 'column2']) 
2. Dataframe.duplicated().sum() or Dataframe.duplicated(subset=['column1', 'column2']).sum()  
Retrive: Dataframe[Dataframe.duplicated()] or Dataframe[Dataframe.duplicated(subset=['column1', 'column2'])]  
Droping Duplicate Values:
1. Dataframe.drop_duplicates() or Dataframe.drop_duplicates(subset=['column1', 'column2'], inplace=True)   
2. Dataframe.drop_duplicates(keep='first', inplace=True)  
3. Dataframe.drop_duplicates(keep='last', inplace=True)

----------------------------------------------------------------------------------------------------------
High Lavel Operations: 
1. Dataframe['column_name'].str.split().apply(lambda x::x[0])  >>Convert this column into string then you can perform any string operations




----------------------------------------------------------------------------------------------------------
Group By: 
1. DataFrame.groupby(by=grouping_column)
2. Aggregation with groupby:
   DataFrame.groupby(by=grouping_column)['column_name'].function() [min,max,sum,avg,mean,median,mode,std,count]
   DataFrame.groupby([column_1,column_2]).agg({'column_3': 'sum', 'column_4': 'mean'})
3. after applying group by, you can perform first,last,nth()
4. Grouped_dataframe.get_group('group_name') 
5. Grouped_dataframe.agg({'column_1':'mean','column_1':'mean',})  >>Agg. Function (Column Based function)
6. Grouped_dataframe.agg(['min','max','mean','sum'......])  >> all function will apply on all columns
7. Grouped_dataframe.nunique()  >> Show all unique values 

----------------------------------------------------------------------------------------------------------
Merge or Join:
1. pd.merge(left_df, right_df, how='inner', on='key_column')   
**Important : how:('inner', 'outer', 'left', 'right') || Except on: left_on='left_column', right_on='right_column' (for different column name)
2. pd.concat([DataFrame1, DataFrame2], axis=0/1)   >> Optional : keys=['New_name_1','New_name_2)]
3. DataFrame1.join(DataFrame2, how='inner')
4. Dataframe1.append(Dataframe1, ignore_index=True)

